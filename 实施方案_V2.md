# OCR文档智能处理系统 - 调整版实施方案 V2

> **更新说明**：基于已跑通的MVP代码进行调整，采用Supabase本地化部署

## 一、项目现状总结

### 1.1 已完成模块 ✅
| 模块 | 文件 | 状态 |
|------|------|------|
| OCR处理 | `text_pipline_ocr.py` | ✅ 已完成 |
| LangGraph工作流 | `supervise_agentic.py` | ✅ 已完成 |
| Prompt配置 | `prompt_config.py` | ✅ 已完成 |
| OCR模型 | `model/` | ✅ 已下载 |

### 1.2 OCR模型路径（已确定）
```
model/
├── PP-OCRv5_server_det_infer/     # 文本检测模型
├── PP-OCRv5_server_rec_infer/     # 文本识别模型
├── PP-LCNet_x1_0_textline_ori_infer/  # 文本行方向模型
└── PP-LCNet_x1_0_doc_ori_infer/   # 文档方向模型
```

### 1.3 待实现模块
- [ ] FastAPI接口层
- [ ] Supabase本地部署
- [ ] 数据库服务层
- [ ] 文件存储服务
- [ ] 用户认证
- [ ] Docker部署

---

## 二、Supabase本地化部署 ⭐

### 2.1 架构变更
```
原方案：Supabase Cloud (托管版)
新方案：Supabase Self-Hosted (本地Docker部署)
```

### 2.2 本地Supabase部署配置

#### 2.2.1 创建 `supabase/docker-compose.yml`

```yaml
# supabase/docker-compose.yml
# Supabase 本地化部署配置

version: "3.8"

services:
  # PostgreSQL 数据库
  db:
    image: supabase/postgres:15.1.0.117
    container_name: supabase-db
    healthcheck:
      test: pg_isready -U postgres -h localhost
      interval: 5s
      timeout: 5s
      retries: 10
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    environment:
      POSTGRES_HOST: /var/run/postgresql
      PGPORT: 5432
      POSTGRES_PORT: 5432
      PGPASSWORD: ${POSTGRES_PASSWORD:-your-super-secret-password}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-your-super-secret-password}
      PGDATABASE: postgres
      POSTGRES_DB: postgres
    volumes:
      - ./volumes/db/data:/var/lib/postgresql/data
      - ./volumes/db/init:/docker-entrypoint-initdb.d
    restart: unless-stopped
    networks:
      - supabase-network

  # Supabase Auth 服务
  auth:
    image: supabase/gotrue:v2.143.0
    container_name: supabase-auth
    depends_on:
      db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9999/health"]
      interval: 5s
      timeout: 5s
      retries: 3
    environment:
      GOTRUE_API_HOST: 0.0.0.0
      GOTRUE_API_PORT: 9999
      API_EXTERNAL_URL: ${API_EXTERNAL_URL:-http://localhost:8000}
      GOTRUE_DB_DRIVER: postgres
      GOTRUE_DB_DATABASE_URL: postgres://supabase_auth_admin:${POSTGRES_PASSWORD:-your-super-secret-password}@db:5432/postgres
      GOTRUE_SITE_URL: ${SITE_URL:-http://localhost:3000}
      GOTRUE_URI_ALLOW_LIST: ${ADDITIONAL_REDIRECT_URLS}
      GOTRUE_DISABLE_SIGNUP: ${DISABLE_SIGNUP:-false}
      GOTRUE_JWT_ADMIN_ROLES: service_role
      GOTRUE_JWT_AUD: authenticated
      GOTRUE_JWT_DEFAULT_GROUP_NAME: authenticated
      GOTRUE_JWT_EXP: ${JWT_EXPIRY:-3600}
      GOTRUE_JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-token-with-at-least-32-characters-long}
      GOTRUE_EXTERNAL_EMAIL_ENABLED: ${ENABLE_EMAIL_SIGNUP:-true}
      GOTRUE_MAILER_AUTOCONFIRM: ${ENABLE_EMAIL_AUTOCONFIRM:-true}
      GOTRUE_SMTP_HOST: ${SMTP_HOST}
      GOTRUE_SMTP_PORT: ${SMTP_PORT:-587}
      GOTRUE_SMTP_USER: ${SMTP_USER}
      GOTRUE_SMTP_PASS: ${SMTP_PASS}
      GOTRUE_SMTP_ADMIN_EMAIL: ${SMTP_ADMIN_EMAIL}
      GOTRUE_SMTP_MAX_FREQUENCY: 1s
      GOTRUE_MAILER_URLPATHS_INVITE: /auth/v1/verify
      GOTRUE_MAILER_URLPATHS_CONFIRMATION: /auth/v1/verify
      GOTRUE_MAILER_URLPATHS_RECOVERY: /auth/v1/verify
      GOTRUE_MAILER_URLPATHS_EMAIL_CHANGE: /auth/v1/verify
    ports:
      - "9999:9999"
    restart: unless-stopped
    networks:
      - supabase-network

  # Supabase REST API (PostgREST)
  rest:
    image: postgrest/postgrest:v11.2.2
    container_name: supabase-rest
    depends_on:
      db:
        condition: service_healthy
    environment:
      PGRST_DB_URI: postgres://authenticator:${POSTGRES_PASSWORD:-your-super-secret-password}@db:5432/postgres
      PGRST_DB_SCHEMAS: public,storage,graphql_public
      PGRST_DB_ANON_ROLE: anon
      PGRST_JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-token-with-at-least-32-characters-long}
      PGRST_DB_USE_LEGACY_GUCS: "false"
    ports:
      - "3000:3000"
    restart: unless-stopped
    networks:
      - supabase-network

  # Supabase Storage 服务
  storage:
    image: supabase/storage-api:v0.43.11
    container_name: supabase-storage
    depends_on:
      db:
        condition: service_healthy
      rest:
        condition: service_started
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:5000/status"]
      interval: 5s
      timeout: 5s
      retries: 3
    environment:
      ANON_KEY: ${ANON_KEY:-eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0}
      SERVICE_KEY: ${SERVICE_ROLE_KEY:-eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImV4cCI6MTk4MzgxMjk5Nn0.EGIM96RAZx35lJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU}
      POSTGREST_URL: http://rest:3000
      PGRST_JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-token-with-at-least-32-characters-long}
      DATABASE_URL: postgres://supabase_storage_admin:${POSTGRES_PASSWORD:-your-super-secret-password}@db:5432/postgres
      FILE_SIZE_LIMIT: 52428800
      STORAGE_BACKEND: file
      FILE_STORAGE_BACKEND_PATH: /var/lib/storage
      TENANT_ID: stub
      REGION: stub
      GLOBAL_S3_BUCKET: stub
      ENABLE_IMAGE_TRANSFORMATION: "true"
      IMGPROXY_URL: http://imgproxy:8080
    volumes:
      - ./volumes/storage:/var/lib/storage
    ports:
      - "5000:5000"
    restart: unless-stopped
    networks:
      - supabase-network

  # Kong API 网关
  kong:
    image: kong:2.8.1
    container_name: supabase-kong
    entrypoint: bash -c 'eval "echo \"$$(cat ~/temp.yml)\"" > ~/kong.yml && /docker-entrypoint.sh kong docker-start'
    depends_on:
      auth:
        condition: service_healthy
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /home/kong/kong.yml
      KONG_DNS_ORDER: LAST,A,CNAME
      KONG_PLUGINS: request-transformer,cors,key-auth,acl,basic-auth
      KONG_NGINX_PROXY_PROXY_BUFFER_SIZE: 160k
      KONG_NGINX_PROXY_PROXY_BUFFERS: 64 160k
      SUPABASE_ANON_KEY: ${ANON_KEY:-eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY:-eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImV4cCI6MTk4MzgxMjk5Nn0.EGIM96RAZx35lJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU}
    volumes:
      - ./kong.yml:/home/kong/temp.yml:ro
    ports:
      - "${KONG_HTTP_PORT:-8000}:8000/tcp"
      - "${KONG_HTTPS_PORT:-8443}:8443/tcp"
    restart: unless-stopped
    networks:
      - supabase-network

  # Supabase Studio (管理界面)
  studio:
    image: supabase/studio:20240101-8e4a094
    container_name: supabase-studio
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/api/profile', (r) => {if (r.statusCode !== 200) throw new Error(r.statusCode)})"]
      interval: 5s
      timeout: 5s
      retries: 3
    depends_on:
      db:
        condition: service_healthy
    environment:
      STUDIO_PG_META_URL: http://meta:8080
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-your-super-secret-password}
      DEFAULT_ORGANIZATION_NAME: ${STUDIO_DEFAULT_ORGANIZATION:-OCR System}
      DEFAULT_PROJECT_NAME: ${STUDIO_DEFAULT_PROJECT:-OCR Document Processor}
      SUPABASE_URL: http://kong:8000
      SUPABASE_PUBLIC_URL: ${SUPABASE_PUBLIC_URL:-http://localhost:8000}
      SUPABASE_ANON_KEY: ${ANON_KEY:-eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY:-eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImV4cCI6MTk4MzgxMjk5Nn0.EGIM96RAZx35lJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU}
    ports:
      - "${STUDIO_PORT:-3001}:3000/tcp"
    restart: unless-stopped
    networks:
      - supabase-network

  # PostgreSQL Meta API
  meta:
    image: supabase/postgres-meta:v0.75.0
    container_name: supabase-meta
    depends_on:
      db:
        condition: service_healthy
    environment:
      PG_META_PORT: 8080
      PG_META_DB_HOST: db
      PG_META_DB_PORT: 5432
      PG_META_DB_NAME: postgres
      PG_META_DB_USER: supabase_admin
      PG_META_DB_PASSWORD: ${POSTGRES_PASSWORD:-your-super-secret-password}
    ports:
      - "8080:8080"
    restart: unless-stopped
    networks:
      - supabase-network

networks:
  supabase-network:
    driver: bridge

volumes:
  db-data:
  storage-data:
```

#### 2.2.2 创建 Kong 网关配置 `supabase/kong.yml`

```yaml
# supabase/kong.yml
_format_version: "2.1"
_transform: true

consumers:
  - username: DASHBOARD
  - username: anon
    keyauth_credentials:
      - key: $SUPABASE_ANON_KEY
  - username: service_role
    keyauth_credentials:
      - key: $SUPABASE_SERVICE_KEY

acls:
  - consumer: anon
    group: anon
  - consumer: service_role
    group: admin

services:
  # Auth API
  - name: auth-v1-open
    url: http://auth:9999/verify
    routes:
      - name: auth-v1-open
        strip_path: true
        paths:
          - /auth/v1/verify
    plugins:
      - name: cors
  - name: auth-v1-open-callback
    url: http://auth:9999/callback
    routes:
      - name: auth-v1-open-callback
        strip_path: true
        paths:
          - /auth/v1/callback
    plugins:
      - name: cors
  - name: auth-v1-open-authorize
    url: http://auth:9999/authorize
    routes:
      - name: auth-v1-open-authorize
        strip_path: true
        paths:
          - /auth/v1/authorize
    plugins:
      - name: cors
  - name: auth-v1
    url: http://auth:9999/
    routes:
      - name: auth-v1
        strip_path: true
        paths:
          - /auth/v1/
    plugins:
      - name: cors
      - name: key-auth
        config:
          hide_credentials: false
      - name: acl
        config:
          hide_groups_header: true
          allow:
            - admin
            - anon

  # REST API (PostgREST)
  - name: rest-v1
    url: http://rest:3000/
    routes:
      - name: rest-v1
        strip_path: true
        paths:
          - /rest/v1/
    plugins:
      - name: cors
      - name: key-auth
        config:
          hide_credentials: true
      - name: acl
        config:
          hide_groups_header: true
          allow:
            - admin
            - anon

  # Storage API
  - name: storage-v1
    url: http://storage:5000/
    routes:
      - name: storage-v1
        strip_path: true
        paths:
          - /storage/v1/
    plugins:
      - name: cors
      - name: key-auth
        config:
          hide_credentials: false
      - name: acl
        config:
          hide_groups_header: true
          allow:
            - admin
            - anon
```

#### 2.2.3 创建环境变量文件 `supabase/.env`

```bash
# supabase/.env
# Supabase 本地部署环境变量

############
# Secrets
# YOU MUST CHANGE THESE BEFORE GOING INTO PRODUCTION
############

# PostgreSQL 密码
POSTGRES_PASSWORD=your-super-secret-and-long-postgres-password

# JWT 密钥 (至少32位)
JWT_SECRET=your-super-secret-jwt-token-with-at-least-32-characters-long

# API Keys (使用 https://supabase.com/docs/guides/self-hosting#api-keys 生成)
ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0
SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImV4cCI6MTk4MzgxMjk5Nn0.EGIM96RAZx35lJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU

############
# Database - 数据库配置
############
POSTGRES_HOST=db
POSTGRES_PORT=5432
POSTGRES_DB=postgres

############
# API - 接口配置
############
SITE_URL=http://localhost:3000
ADDITIONAL_REDIRECT_URLS=
JWT_EXPIRY=3600
DISABLE_SIGNUP=false

############
# API 网关端口
############
KONG_HTTP_PORT=8000
KONG_HTTPS_PORT=8443

############
# Studio - 管理界面配置
############
STUDIO_PORT=3001
SUPABASE_PUBLIC_URL=http://localhost:8000
STUDIO_DEFAULT_ORGANIZATION=OCR System
STUDIO_DEFAULT_PROJECT=OCR Document Processor

############
# Email - 邮件配置 (可选)
############
ENABLE_EMAIL_SIGNUP=true
ENABLE_EMAIL_AUTOCONFIRM=true
SMTP_HOST=
SMTP_PORT=587
SMTP_USER=
SMTP_PASS=
SMTP_ADMIN_EMAIL=
```

### 2.3 启动Supabase本地服务

```bash
# 1. 进入supabase目录
cd supabase

# 2. 创建数据卷目录
mkdir -p volumes/db/data volumes/db/init volumes/storage

# 3. 启动所有服务
docker-compose up -d

# 4. 查看服务状态
docker-compose ps

# 5. 查看日志
docker-compose logs -f
```

### 2.4 本地Supabase访问地址
| 服务 | 地址 | 说明 |
|------|------|------|
| **Supabase Studio** | http://localhost:3001 | 管理界面 |
| **API Gateway** | http://localhost:8000 | Kong网关 |
| **REST API** | http://localhost:8000/rest/v1/ | PostgREST |
| **Auth API** | http://localhost:8000/auth/v1/ | GoTrue |
| **Storage API** | http://localhost:8000/storage/v1/ | Storage |
| **PostgreSQL** | localhost:5432 | 数据库直连 |

---

## 三、调整后的项目结构

```
ocr_agentic_system/
├── api/                        # FastAPI 应用层
│   ├── __init__.py
│   ├── main.py                # FastAPI 主应用
│   ├── routes/
│   │   ├── documents.py       # 文档处理路由
│   │   ├── health.py          # 健康检查
│   │   └── users.py           # 用户管理
│   ├── dependencies.py        # 依赖注入
│   └── schemas.py             # Pydantic 模型
│
├── agents/                     # LangGraph 智能体
│   ├── __init__.py
│   ├── workflow.py            # 主工作流 (基于 supervise_agentic.py)
│   └── state.py               # 状态定义
│
├── services/                   # 业务服务层
│   ├── __init__.py
│   ├── ocr_service.py         # OCR服务 (基于 text_pipline_ocr.py)
│   ├── supabase_service.py    # Supabase服务
│   └── document_service.py    # 文档处理服务
│
├── config/                     # 配置文件
│   ├── __init__.py
│   ├── settings.py            # 应用配置
│   └── prompts.py             # Prompt配置 (来自 prompt_config.py)
│
├── model/                      # OCR模型 [已存在]
│   ├── PP-OCRv5_server_det_infer/
│   ├── PP-OCRv5_server_rec_infer/
│   ├── PP-LCNet_x1_0_textline_ori_infer/
│   └── PP-LCNet_x1_0_doc_ori_infer/
│
├── supabase/                   # Supabase本地部署
│   ├── docker-compose.yml
│   ├── kong.yml
│   ├── .env
│   ├── migrations/            # 数据库迁移脚本
│   │   └── 001_init.sql
│   └── volumes/               # 数据卷 (gitignore)
│
├── uploads/                    # 文件上传目录
├── logs/                       # 日志目录
│
├── .env                        # 应用环境变量
├── .env.example               # 环境变量模板
├── requirements.txt           # Python依赖
├── Dockerfile                 # 应用Docker配置
├── docker-compose.yml         # 完整服务编排
│
├── text_pipline_ocr.py        # [MVP代码] OCR处理
├── supervise_agentic.py       # [MVP代码] LangGraph工作流
├── prompt_config.py           # [MVP代码] Prompt配置
│
└── README.md
```

---

## 四、配置文件更新

### 4.1 环境变量配置 `.env`

```bash
# .env - 应用环境变量配置

# ============ 应用基础配置 ============
APP_NAME=OCR-Document-Processor
DEBUG=true
HOST=0.0.0.0
PORT=8080

# ============ 安全配置 ============
SECRET_KEY=your-app-secret-key-change-in-production
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# ============ Supabase本地配置 ============
# 本地部署地址
SUPABASE_URL=http://localhost:8000
SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImV4cCI6MTk4MzgxMjk5Nn0.EGIM96RAZx35lJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU

# PostgreSQL直连 (可选，用于数据库迁移)
DATABASE_URL=postgresql://postgres:your-super-secret-and-long-postgres-password@localhost:5432/postgres

# ============ LLM配置 ============
LLM_MODEL_ID=gpt-4o-mini
LLM_API_KEY=sk-your-openai-api-key
LLM_BASE_URL=https://api.openai.com/v1
LLM_TEMPERATURE=0.7

# 可选：使用DeepSeek
# LLM_MODEL_ID=deepseek-chat
# LLM_BASE_URL=https://api.deepseek.com

# ============ OCR模型配置 ============
OCR_DET_MODEL_PATH=./model/PP-OCRv5_server_det_infer
OCR_REC_MODEL_PATH=./model/PP-OCRv5_server_rec_infer
OCR_ORI_MODEL_PATH=./model/PP-LCNet_x1_0_textline_ori_infer
OCR_DOC_MODEL_PATH=./model/PP-LCNet_x1_0_doc_ori_infer

# ============ 文件存储配置 ============
UPLOAD_FOLDER=./uploads
MAX_FILE_SIZE=20971520
ALLOWED_EXTENSIONS=.pdf,.png,.jpg,.jpeg,.tiff,.bmp

# ============ 日志配置 ============
LOG_LEVEL=INFO
LOG_FILE=./logs/app.log
```

### 4.2 Python依赖 `requirements.txt`

```txt
# requirements.txt - Python依赖清单

# Web框架
fastapi==0.109.0
uvicorn[standard]==0.27.0
python-multipart==0.0.6

# 数据验证
pydantic==2.5.3
pydantic-settings==2.1.0
email-validator==2.1.0

# Supabase
supabase==2.3.4
postgrest==0.16.1

# LangChain & LangGraph
langchain==0.1.0
langchain-openai==0.0.5
langchain-core==0.1.10
langgraph==0.0.26

# OCR
paddlepaddle==2.6.0
paddleocr==2.7.3
opencv-python-headless==4.9.0.80

# 工具库
python-dotenv==1.0.0
aiofiles==23.2.1
httpx==0.26.0
tenacity==8.2.3

# 图像处理
Pillow==10.2.0
pdf2image==1.17.0

# 日志
loguru==0.7.2

# 开发依赖
pytest==7.4.4
pytest-asyncio==0.23.3
```

---

## 五、核心代码重构

### 5.1 配置管理 `config/settings.py`

```python
# config/settings.py
from pydantic_settings import BaseSettings
from pydantic import Field
from typing import Optional
import os

class Settings(BaseSettings):
    """应用配置"""
    
    # 基础配置
    APP_NAME: str = "OCR-Document-Processor"
    DEBUG: bool = True
    HOST: str = "0.0.0.0"
    PORT: int = 8080
    
    # 安全配置
    SECRET_KEY: str = "your-secret-key"
    JWT_ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    
    # Supabase配置 (本地部署)
    SUPABASE_URL: str = "http://localhost:8000"
    SUPABASE_ANON_KEY: str
    SUPABASE_SERVICE_ROLE_KEY: str
    DATABASE_URL: Optional[str] = None
    
    # LLM配置
    LLM_MODEL_ID: str = "gpt-4o-mini"
    LLM_API_KEY: str
    LLM_BASE_URL: str = "https://api.openai.com/v1"
    LLM_TEMPERATURE: float = 0.7
    
    # OCR模型路径
    OCR_DET_MODEL_PATH: str = "./model/PP-OCRv5_server_det_infer"
    OCR_REC_MODEL_PATH: str = "./model/PP-OCRv5_server_rec_infer"
    OCR_ORI_MODEL_PATH: str = "./model/PP-LCNet_x1_0_textline_ori_infer"
    OCR_DOC_MODEL_PATH: str = "./model/PP-LCNet_x1_0_doc_ori_infer"
    
    # 文件存储
    UPLOAD_FOLDER: str = "./uploads"
    MAX_FILE_SIZE: int = 20971520  # 20MB
    ALLOWED_EXTENSIONS: str = ".pdf,.png,.jpg,.jpeg,.tiff,.bmp"
    
    # 日志
    LOG_LEVEL: str = "INFO"
    LOG_FILE: str = "./logs/app.log"
    
    @property
    def allowed_extensions_list(self) -> list:
        return [ext.strip() for ext in self.ALLOWED_EXTENSIONS.split(",")]
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

# 单例
settings = Settings()
```

### 5.2 OCR服务重构 `services/ocr_service.py`

```python
# services/ocr_service.py
"""OCR服务 - 基于MVP代码重构"""

import os
import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any, Optional
from paddleocr import PaddleOCR
from loguru import logger

from config.settings import settings


class OCRService:
    """PaddleOCR 服务封装"""
    
    _instance: Optional['OCRService'] = None
    _initialized: bool = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.ocr_engine: Optional[PaddleOCR] = None
            self.executor = ThreadPoolExecutor(max_workers=2)
            self._watermarks = ['no', 'noi', 'copy', '样本', '仅供参考']
            self._threshold = 0.5
            OCRService._initialized = True
    
    async def initialize(self) -> bool:
        """异步初始化OCR引擎"""
        try:
            # 验证模型路径
            model_paths = {
                "检测模型": settings.OCR_DET_MODEL_PATH,
                "识别模型": settings.OCR_REC_MODEL_PATH,
                "方向模型": settings.OCR_ORI_MODEL_PATH,
                "文档模型": settings.OCR_DOC_MODEL_PATH
            }
            
            for name, path in model_paths.items():
                if not os.path.exists(path):
                    raise FileNotFoundError(f"{name}路径不存在: {path}")
                logger.info(f"✓ {name}: {path}")
            
            # 异步初始化
            loop = asyncio.get_event_loop()
            self.ocr_engine = await loop.run_in_executor(
                self.executor, self._init_ocr_sync
            )
            
            logger.info("✓ OCR引擎初始化成功")
            return True
            
        except Exception as e:
            logger.error(f"✗ OCR引擎初始化失败: {e}")
            raise
    
    def _init_ocr_sync(self) -> PaddleOCR:
        """同步初始化PaddleOCR"""
        return PaddleOCR(
            lang='ch',
            det_model_dir=settings.OCR_DET_MODEL_PATH,
            rec_model_dir=settings.OCR_REC_MODEL_PATH,
            textline_orientation_model_dir=settings.OCR_ORI_MODEL_PATH,
            doc_orientation_classify_model_dir=settings.OCR_DOC_MODEL_PATH,
            use_doc_orientation_classify=True,
            use_doc_unwarping=False,
            det_limit_side_len=960,
            det_limit_type='max',
            use_angle_cls=True,
            show_log=False
        )
    
    async def process_document(self, file_path: str) -> Dict[str, Any]:
        """处理单个文档
        
        Returns:
            {
                "text": str,           # 提取的文本
                "confidence": float,   # 平均置信度
                "lines": List[Dict]    # 每行详细信息
            }
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"文件不存在: {file_path}")
        
        if not self.ocr_engine:
            await self.initialize()
        
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            self.executor, 
            self._process_sync, 
            file_path
        )
        
        return result
    
    def _process_sync(self, file_path: str) -> Dict[str, Any]:
        """同步执行OCR"""
        result = self.ocr_engine.predict(input=file_path)
        
        lines = []
        total_score = 0
        valid_count = 0
        
        for page_result in result:
            texts = page_result.get("rec_texts", [])
            scores = page_result.get("rec_scores", [])
            
            for text, score in zip(texts, scores):
                text = text.strip()
                # 过滤低置信度和水印
                if (score >= self._threshold 
                    and text 
                    and not any(wm in text.lower() for wm in self._watermarks)):
                    lines.append({
                        "text": text,
                        "confidence": float(score)
                    })
                    total_score += score
                    valid_count += 1
        
        # 计算平均置信度
        avg_confidence = total_score / valid_count if valid_count > 0 else 0.0
        
        # 合并文本
        full_text = "\n".join([line["text"] for line in lines])
        
        return {
            "text": full_text,
            "confidence": avg_confidence,
            "lines": lines,
            "total_lines": len(lines)
        }
    
    async def process_batch(self, file_paths: List[str]) -> Dict[str, Any]:
        """批量处理文档"""
        tasks = [self.process_document(path) for path in file_paths]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        output = {}
        for path, result in zip(file_paths, results):
            if isinstance(result, Exception):
                output[path] = {"error": str(result)}
            else:
                output[path] = result
        
        return output
    
    async def close(self):
        """关闭服务"""
        if self.executor:
            self.executor.shutdown(wait=True)
            logger.info("OCR服务已关闭")


# 单例实例
ocr_service = OCRService()
```

### 5.3 LangGraph工作流重构 `agents/workflow.py`

```python
# agents/workflow.py
"""LangGraph OCR处理工作流 - 基于MVP代码重构"""

import json
import asyncio
from typing import TypedDict, Annotated, Any, Dict, Optional
from datetime import datetime

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from loguru import logger

from config.settings import settings
from config.prompts import (
    DOC_CLASSIFY_PROMPT, 
    TEXTREPORT_PROMPT, 
    EXPRESS_PROMPT, 
    SAMPLING_FORM_PROMPT
)
from services.ocr_service import ocr_service


class WorkflowState(TypedDict):
    """工作流状态定义"""
    messages: Annotated[list, add_messages]
    document_id: str
    file_path: str
    ocr_text: str
    ocr_confidence: float
    document_type: str
    extraction_data: dict
    step: str
    error: Optional[str]
    processing_start: datetime


class OCRWorkflow:
    """OCR处理工作流"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=settings.LLM_MODEL_ID,
            api_key=settings.LLM_API_KEY,
            base_url=settings.LLM_BASE_URL,
            temperature=settings.LLM_TEMPERATURE,
        )
        self.memory = MemorySaver()
        self.workflow = self._build_workflow()
    
    def _build_workflow(self) -> StateGraph:
        """构建工作流"""
        workflow = StateGraph(WorkflowState)
        
        # 添加节点
        workflow.add_node("ocr_extract", self._ocr_node)
        workflow.add_node("classify", self._classify_node)
        workflow.add_node("extract_fields", self._extract_node)
        
        # 定义边
        workflow.add_edge(START, "ocr_extract")
        workflow.add_edge("ocr_extract", "classify")
        workflow.add_edge("classify", "extract_fields")
        workflow.add_edge("extract_fields", END)
        
        return workflow.compile(checkpointer=self.memory)
    
    async def _ocr_node(self, state: WorkflowState) -> WorkflowState:
        """OCR提取节点"""
        try:
            logger.info(f"开始OCR处理: {state['file_path']}")
            
            result = await ocr_service.process_document(state["file_path"])
            
            logger.info(f"OCR完成，提取{result['total_lines']}行，置信度{result['confidence']:.2f}")
            
            return {
                **state,
                "ocr_text": result["text"],
                "ocr_confidence": result["confidence"],
                "step": "ocr_completed",
                "messages": [AIMessage(content=f"OCR提取完成，共{result['total_lines']}行文本")]
            }
            
        except Exception as e:
            logger.error(f"OCR处理失败: {e}")
            return {**state, "error": str(e), "step": "ocr_failed"}
    
    async def _classify_node(self, state: WorkflowState) -> WorkflowState:
        """文档分类节点"""
        try:
            ocr_text = state.get("ocr_text", "")
            
            if not ocr_text:
                raise ValueError("OCR文本为空，无法分类")
            
            logger.info("开始文档分类...")
            
            prompt = DOC_CLASSIFY_PROMPT.format(ocr_result=ocr_text[:2000])
            response = await self.llm.ainvoke(prompt)
            
            # 解析响应
            try:
                data = json.loads(response.content)
                doc_type = data.get("文档类型", "未知")
            except json.JSONDecodeError:
                # 回退：关键词匹配
                doc_type = self._fallback_classify(ocr_text)
            
            logger.info(f"文档分类结果: {doc_type}")
            
            return {
                **state,
                "document_type": doc_type,
                "step": "classified",
                "messages": [AIMessage(content=f"文档分类完成: {doc_type}")]
            }
            
        except Exception as e:
            logger.error(f"分类失败: {e}")
            return {**state, "error": str(e), "step": "classify_failed"}
    
    async def _extract_node(self, state: WorkflowState) -> WorkflowState:
        """字段提取节点"""
        try:
            doc_type = state.get("document_type", "")
            ocr_text = state.get("ocr_text", "")
            
            logger.info(f"开始字段提取，文档类型: {doc_type}")
            
            # 根据文档类型选择Prompt
            if doc_type == "测试单":
                prompt = f"{TEXTREPORT_PROMPT}\n\nOCR文本：\n{ocr_text}"
            elif doc_type == "快递单":
                prompt = f"{EXPRESS_PROMPT}\n\nOCR文本：\n{ocr_text}"
            elif doc_type == "抽样单":
                prompt = f"{SAMPLING_FORM_PROMPT}\n\nOCR文本：\n{ocr_text}"
            else:
                return {
                    **state,
                    "extraction_data": {"error": f"不支持的文档类型: {doc_type}"},
                    "step": "extract_failed"
                }
            
            response = await self.llm.ainvoke(prompt)
            
            # 解析JSON
            try:
                extraction_data = json.loads(response.content)
            except json.JSONDecodeError:
                # 尝试清理后解析
                extraction_data = self._clean_json_response(response.content)
            
            logger.info(f"字段提取完成: {len(extraction_data)}个字段")
            
            return {
                **state,
                "extraction_data": extraction_data,
                "step": "completed",
                "messages": [AIMessage(content="字段提取完成")]
            }
            
        except Exception as e:
            logger.error(f"提取失败: {e}")
            return {**state, "error": str(e), "step": "extract_failed"}
    
    def _fallback_classify(self, text: str) -> str:
        """关键词回退分类"""
        text_lower = text.lower()
        
        if any(kw in text for kw in ["运单号", "快递单号", "收件人", "寄件人", "物流"]):
            return "快递单"
        elif any(kw in text for kw in ["抽样编号", "抽样基数", "备样量", "被抽样单位"]):
            return "抽样单"
        elif any(kw in text for kw in ["检测项目", "检测结果", "检验依据", "检验结论"]):
            return "测试单"
        else:
            return "未知"
    
    def _clean_json_response(self, content: str) -> dict:
        """清理LLM响应中的JSON"""
        # 移除可能的Markdown代码块
        content = content.strip()
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
        
        try:
            return json.loads(content.strip())
        except:
            return {"raw_response": content}
    
    async def process(self, document_id: str, file_path: str) -> Dict[str, Any]:
        """执行工作流
        
        Args:
            document_id: 文档ID
            file_path: 文件路径
            
        Returns:
            处理结果字典
        """
        initial_state = WorkflowState(
            messages=[],
            document_id=document_id,
            file_path=file_path,
            ocr_text="",
            ocr_confidence=0.0,
            document_type="",
            extraction_data={},
            step="start",
            error=None,
            processing_start=datetime.now()
        )
        
        config = {"configurable": {"thread_id": document_id}}
        
        try:
            final_state = await self.workflow.ainvoke(initial_state, config=config)
            
            processing_time = (datetime.now() - initial_state["processing_start"]).total_seconds()
            
            return {
                "success": final_state.get("error") is None,
                "document_id": document_id,
                "document_type": final_state.get("document_type"),
                "extraction_data": final_state.get("extraction_data"),
                "ocr_confidence": final_state.get("ocr_confidence"),
                "processing_time": processing_time,
                "step": final_state.get("step"),
                "error": final_state.get("error")
            }
            
        except Exception as e:
            logger.error(f"工作流执行失败: {e}")
            return {
                "success": False,
                "document_id": document_id,
                "error": str(e)
            }


# 单例工作流
ocr_workflow = OCRWorkflow()
```

### 5.4 Supabase服务 `services/supabase_service.py`

```python
# services/supabase_service.py
"""Supabase 数据库服务 - 本地部署版"""

from typing import Optional, Dict, Any, List
from datetime import datetime
from supabase import create_client, Client
from loguru import logger

from config.settings import settings


class SupabaseService:
    """Supabase 服务封装"""
    
    _instance: Optional['SupabaseService'] = None
    _client: Optional[Client] = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    async def initialize(self):
        """初始化Supabase客户端"""
        try:
            self._client = create_client(
                settings.SUPABASE_URL,
                settings.SUPABASE_SERVICE_ROLE_KEY
            )
            logger.info(f"✓ Supabase连接成功: {settings.SUPABASE_URL}")
            return True
        except Exception as e:
            logger.error(f"✗ Supabase连接失败: {e}")
            raise
    
    @property
    def client(self) -> Client:
        if not self._client:
            raise RuntimeError("Supabase未初始化，请先调用initialize()")
        return self._client
    
    # ============ 文档操作 ============
    
    async def create_document(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """创建文档记录"""
        result = self.client.table("documents").insert(data).execute()
        return result.data[0] if result.data else None
    
    async def get_document(self, document_id: str) -> Optional[Dict[str, Any]]:
        """获取文档"""
        result = self.client.table("documents").select("*").eq("id", document_id).execute()
        return result.data[0] if result.data else None
    
    async def update_document(self, document_id: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """更新文档"""
        result = self.client.table("documents").update(data).eq("id", document_id).execute()
        return result.data[0] if result.data else None
    
    async def update_document_status(
        self, 
        document_id: str, 
        status: str, 
        error_message: Optional[str] = None
    ):
        """更新文档状态"""
        data = {"status": status}
        if error_message:
            data["error_message"] = error_message
        if status == "completed":
            data["processed_at"] = datetime.now().isoformat()
        
        return await self.update_document(document_id, data)
    
    async def list_documents(
        self,
        user_id: Optional[str] = None,
        status: Optional[str] = None,
        document_type: Optional[str] = None,
        page: int = 1,
        limit: int = 20
    ) -> List[Dict[str, Any]]:
        """列出文档"""
        query = self.client.table("documents").select("*")
        
        if user_id:
            query = query.eq("user_id", user_id)
        if status:
            query = query.eq("status", status)
        if document_type:
            query = query.eq("document_type", document_type)
        
        offset = (page - 1) * limit
        query = query.order("created_at", desc=True).range(offset, offset + limit - 1)
        
        result = query.execute()
        return result.data
    
    # ============ 检验报告操作 ============
    
    async def save_inspection_report(self, document_id: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """保存检验报告"""
        data["document_id"] = document_id
        data["raw_extraction_data"] = data.copy()
        result = self.client.table("inspection_reports").upsert(data).execute()
        return result.data[0] if result.data else None
    
    # ============ 快递单操作 ============
    
    async def save_express(self, document_id: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """保存快递单"""
        data["document_id"] = document_id
        data["raw_extraction_data"] = data.copy()
        result = self.client.table("expresses").upsert(data).execute()
        return result.data[0] if result.data else None
    
    # ============ 抽样单操作 ============
    
    async def save_sampling_form(self, document_id: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """保存抽样单"""
        data["document_id"] = document_id
        data["raw_extraction_data"] = data.copy()
        result = self.client.table("sampling_forms").upsert(data).execute()
        return result.data[0] if result.data else None
    
    # ============ 通用保存方法 ============
    
    async def save_extraction_result(
        self, 
        document_id: str, 
        document_type: str, 
        extraction_data: Dict[str, Any]
    ):
        """根据文档类型保存提取结果"""
        if document_type == "测试单":
            return await self.save_inspection_report(document_id, extraction_data)
        elif document_type == "快递单":
            return await self.save_express(document_id, extraction_data)
        elif document_type == "抽样单":
            return await self.save_sampling_form(document_id, extraction_data)
        else:
            logger.warning(f"未知文档类型: {document_type}")
            return None
    
    # ============ 处理日志 ============
    
    async def log_processing(
        self,
        document_id: str,
        step: str,
        status: str,
        message: Optional[str] = None,
        duration_ms: Optional[int] = None
    ):
        """记录处理日志"""
        data = {
            "document_id": document_id,
            "step": step,
            "status": status,
            "message": message,
            "duration_ms": duration_ms
        }
        result = self.client.table("processing_logs").insert(data).execute()
        return result.data[0] if result.data else None


# 单例实例
supabase_service = SupabaseService()
```

---

## 六、调整后的实施计划

### 6.1 新阶段划分

| 阶段 | 内容 | 时间 | 状态 |
|------|------|------|------|
| **Phase 0** | MVP验证 | - | ✅ 已完成 |
| **Phase 1** | Supabase本地部署 | 1天 | 待开始 |
| **Phase 2** | 代码重构与整合 | 2天 | 待开始 |
| **Phase 3** | FastAPI接口开发 | 2天 | 待开始 |
| **Phase 4** | 数据库集成 | 1天 | 待开始 |
| **Phase 5** | Docker部署 | 1天 | 待开始 |
| **Phase 6** | 测试与优化 | 2天 | 待开始 |

**总计：9天（比原方案减少约50%）**

### 6.2 详细任务清单

#### Phase 1: Supabase本地部署 (Day 1)
- [ ] 创建 `supabase/` 目录结构
- [ ] 配置 `docker-compose.yml`
- [ ] 配置 Kong 网关
- [ ] 启动并验证服务
- [ ] 执行数据库迁移脚本

#### Phase 2: 代码重构 (Day 2-3)
- [ ] 创建 `config/settings.py`
- [ ] 重构 `services/ocr_service.py`
- [ ] 重构 `agents/workflow.py`
- [ ] 创建 `services/supabase_service.py`
- [ ] 迁移 `prompt_config.py` 到 `config/prompts.py`

#### Phase 3: FastAPI接口 (Day 4-5)
- [ ] 创建 `api/main.py`
- [ ] 创建 `api/routes/documents.py`
- [ ] 创建 `api/routes/health.py`
- [ ] 创建 `api/schemas.py`
- [ ] 添加文件上传处理

#### Phase 4: 数据库集成 (Day 6)
- [ ] 集成Supabase客户端
- [ ] 实现文档CRUD
- [ ] 实现结果存储
- [ ] 测试RLS策略

#### Phase 5: Docker部署 (Day 7)
- [ ] 创建应用 Dockerfile
- [ ] 创建完整 docker-compose.yml
- [ ] 配置Nginx反向代理
- [ ] 测试部署流程

#### Phase 6: 测试优化 (Day 8-9)
- [ ] 编写单元测试
- [ ] API集成测试
- [ ] 性能测试
- [ ] 文档完善

---

## 七、关键变更对比

| 项目 | 原方案 | 调整后 |
|------|--------|--------|
| **Supabase** | 云托管 | 本地Docker部署 |
| **OCR模型** | 待下载 | 已下载就绪 |
| **Prompt** | 待编写 | 已完成 |
| **工作流** | 待实现 | MVP已验证 |
| **开发周期** | 12-19天 | 9天 |
| **依赖管理** | 待定义 | 明确版本 |

---

## 八、快速启动指南

### 8.1 一键启动开发环境

```bash
# 1. 克隆/进入项目
cd ocr_agentic_system

# 2. 创建虚拟环境
python -m venv venv
.\venv\Scripts\activate  # Windows

# 3. 安装依赖
pip install -r requirements.txt

# 4. 启动Supabase本地服务
cd supabase
docker-compose up -d
cd ..

# 5. 配置环境变量
copy .env.example .env
# 编辑 .env 填入 LLM_API_KEY

# 6. 执行数据库迁移
# 通过 Supabase Studio (http://localhost:3001) 执行SQL

# 7. 启动应用
uvicorn api.main:app --reload --port 8080
```

### 8.2 验证服务

```bash
# 检查API健康状态
curl http://localhost:8080/api/health

# 检查Supabase
curl http://localhost:8000/rest/v1/ -H "apikey: YOUR_ANON_KEY"

# 上传并处理文档 (API开发完成后)
curl -X POST http://localhost:8080/api/documents/upload \
  -F "file=@test.pdf"
```

---

## 九、总结

### 调整后的优势：
1. ✅ **基于已验证的MVP**，风险大幅降低
2. ✅ **Supabase本地化**，完全掌控数据
3. ✅ **OCR模型就绪**，无需额外配置
4. ✅ **Prompt已优化**，可直接使用
5. ✅ **开发周期缩短50%**

### 注意事项：
- ⚠️ Supabase本地部署需要至少8GB内存
- ⚠️ 首次启动可能需要5-10分钟下载镜像
- ⚠️ 生产环境需更换默认密钥和JWT密钥

